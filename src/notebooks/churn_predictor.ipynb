{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3cc924-455a-4ef0-9568-818eaa7c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from preprocessing import build_preprocessor, PreprocessConfig\n",
    "from models.model import build_model, make_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f953d8cf-3004-4777-b057-1dfa776f0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChurnPredictor:\n",
    "    def __init__(self, drop_cols=None, corr_threshold=None, expect_numeric=True):\n",
    "        self.cfg = PreprocessConfig(drop_cols=drop_cols, corr_threshold=corr_threshold, expect_numeric=expect_numeric)\n",
    "        self.preprocessor = None\n",
    "        self.feature_names_ = None\n",
    "        self.tuner = None\n",
    "        self.best_hp = None\n",
    "        self.model = None\n",
    "\n",
    "    def split(self, df:pd.DataFrame, y_col='Churn', test_size=0.2, val_size=0.5, seed=42):\n",
    "        X_df = df.drop(columns=[y_col])\n",
    "        y = df[y_col].values\n",
    "\n",
    "        # Split train(0.8) test(0.1) val(0.1)\n",
    "        X_train_full, X_temp, y_train_full, y_temp = train_test_split(\n",
    "            X_df, y, test_size=test_size, stratify=y, random_state=seed)\n",
    "        X_valid, X_test, y_valid, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_size, stratify=y_temp, random_state=seed)\n",
    "        self._splits = (X_train_full, X_valid, X_test, y_train_full, y_valid, y_test)\n",
    "        return self._splits\n",
    "\n",
    "    def preprocess_fit(self, X_train_full:pd.DataFrame):\n",
    "        self.preprocessor, get_names = build_preprocessor(X_train_full, self.cfg)\n",
    "        self.preprocessor.fit(X_train_full)\n",
    "        self.feature_names_ = get_names()\n",
    "        return self\n",
    "\n",
    "    def transform_all(self, X_train_full, X_valid, X_test):\n",
    "        X_tr = self.preprocessor.transform(X_train_full)\n",
    "        X_va = self.preprocessor.transform(X_valid)\n",
    "        X_te = self.preprocessor.transform(X_test)\n",
    "        return X_tr, X_va, X_te\n",
    "\n",
    "    def tune(self, X_tr, y_tr, X_va, y_va, project_name='krs_hyperband'):\n",
    "        self.tuner = make_tuner(input_dim=X_tr.shape[1], project_name=project_name)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "        self.tuner.search(X_tr, y_tr, validation_data=(X_va, y_va), callbacks=[early_stop], verbose=1)\n",
    "        self.best_hp = self.tuner.get_best_hyperparameters(1)[0]\n",
    "        return self.best_hp\n",
    "        \n",
    "    def pick_best_params(self, min_val_acc=0.78, keys=('units1', 'units2', 'units3', 'lr')):\n",
    "        if self.tuner in None and self.best_hp is None:\n",
    "            raise RuntimeError(\"Run tune() first or set best_hp.\")\n",
    "        trials = [t for t in tuner.oracle.get_best_trials() if t.status == \"COMPLETED\"]\n",
    "        trials = [t for t in trials\n",
    "                 if t.metrics.get_last_value(\"val_accuracy\") is not None \n",
    "                 and t.metrics.get_last_value(\"val_accuracy\") >= min_val_acc\n",
    "                 and t.metrics.get_last_value(\"val_auprc\") is not None]\n",
    "        \n",
    "        if not trials:\n",
    "                hp = self.best_hp\n",
    "                return {k:hp.get(k) for k in keys}\n",
    "            \n",
    "        best = max(trials, key=lambda t: t.metrics.get_last_value(\"val_auprc\"))\n",
    "        hpv = best.hyperparameters.values\n",
    "        return {k:hpv[k] for k in keys}\n",
    "\n",
    "    def compute_class_weight(self, y):\n",
    "        classes = np.unique(y)\n",
    "        w = class_weight.compute_class_weight(\n",
    "        class_weight='balanced', \n",
    "        classes=classes, \n",
    "        y=y)\n",
    "        return dict(enumerate(w))\n",
    "\n",
    "    def fit_final(self, X_tr, y_tr, X_va, y_va, \n",
    "                  best_params:dict, epochs=50, batch_size=32, class_weights=None, \n",
    "                  save_path:str | None=None, use_gpu: bool=True, use_mixed_precision: bool=False):\n",
    "        # Speed up tuning and training time\n",
    "        policy_ctx = None\n",
    "        if use_mixed_precision:\n",
    "            mp.set_global_policy('mixed_float16')\n",
    "            \n",
    "        tf.keras.backend.clear_session()\n",
    "        self.model = build_model(X_tr.shape[1], **best_params)\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "\n",
    "        device_name = '/GPU:0' if (use_gpu and tf.config.list_physical_devices('GPU')) else 'CPU:0' # Choose device if available\n",
    "        start = time.perf_counter()\n",
    "        with tf.device(device_name):\n",
    "            history = self.model.fit(X_tr, y_tr, \n",
    "                    validation_data=(X_va, y_va), \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=callbacks, \n",
    "                    class_weights=class_weights,\n",
    "                    verbose=0)\n",
    "        train_time_sec = time.perf_counter() - start\n",
    "\n",
    "        # Save best model\n",
    "        if save_path:\n",
    "            self.model.save(save_path)\n",
    "            \n",
    "        return history, train_time_sec\n",
    "\n",
    "    def evaluate(self, X_te, y_te):\n",
    "        results = self.model.evaluate(X_te, y_te, verbose=0)\n",
    "\n",
    "        # This model calculates accuracy and auprc, change other metrics here\n",
    "        if isinstance(results, (list, tuple)) and len(results) >= 3:\n",
    "            loss, auprc, acc = results[:3]\n",
    "            return {\"loss\": loss, \"auprc\": auprc, \"accuracy\": acc} # For readibility\n",
    "        return results\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.model.predict(X, verbose=0).ravel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
